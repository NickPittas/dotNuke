set cut_paste_input [stack 0]
version 14.0 v2
push $cut_paste_input
NoOp {
name NoOp1
selected true
xpos -608
ypos -512
addUserKnob {20 User}
addUserKnob {3 start_frame l "Start Frame"}
start_frame 1
addUserKnob {3 end_frame l "End Frame"}
end_frame 100
addUserKnob {22 _1 l Python T "import cv2\nimport nuke\nimport os\nnode=nuke.thisNode()\nscaleFactor=node.knob('scaleFactor').getValue()\nminNeighbors=node.knob('minNeighbors').getValue()\nminSizeX=node.knob('minSizeX').getValue()\nminSizeY=node.knob('minSizeY').getValue()\nminSize=minSizeX, minSizeY\nprint(minSize)\nstart_frame=int(node.knob('start_frame').getValue())\nend_frame=int(node.knob('end_frame').getValue())\n\ndef track_face(read_node, start_frame, end_frame):\n    # Load the face detection model\n    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n    # Initialize the Tracker node\n    tracker_node = nuke.createNode('Tracker4')\n    tracker_node\['tracks'].setAnimated()\n\n    # Get the file path and image height\n    file_path = read_node\['file'].getValue()\n    img_height = int(read_node\['format'].value().height())\n\n    # Open the video file\n    video_capture = cv2.VideoCapture(file_path)\n    if not video_capture.isOpened():\n        nuke.message(\"Error opening video file.\")\n        return\n\n    # Process each frame in the specified range\n    for frame in range(start_frame, end_frame + 1):\n        # Read the current frame\n        video_capture.set(cv2.CAP_PROP_POS_FRAMES, frame)\n        ret, current_frame = video_capture.read()\n\n        # Check if the frame is read successfully\n        if not ret:\n            print(f\"Error reading frame \{frame\} from \{file_path\}.\")\n            continue\n\n        # Convert the frame to grayscale\n        gray_frame = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n\n        # Detect faces in the frame\n        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=scaleFactor, minNeighbors=int(minNeighbors), minSize=(int(minSizeX), int(minSizeY)))\n\n        # Update the Tracker node with the face location and draw rectangles around detected faces\n        for index, (x, y, w, h) in enumerate(faces):\n            center_x, center_y = x + w / 2, y + h / 2\n\n            # Adjust the Y position based on the image height\n            center_y = img_height - center_y\n\n            # Add a new track if necessary\n            if frame == start_frame:\n                k = tracker_node\['tracks']\n                numColumns = 31\n                colTrackX = 2\n                colTrackY = 3\n                tracker_node\[\"add_track\"].execute()\n\n            # Set the track position\n            tracker_node\['tracks'].setValueAt(center_x, frame, colTrackX)\n            tracker_node\['tracks'].setValueAt(center_y, frame, colTrackY)\n\n            # Draw a rectangle around the face\n            cv2.rectangle(current_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n\n            # Break the loop after processing the first detected face\n            break\n\n        # Display the current frame with the tracked face\n        cv2.imshow('Tracking', current_frame)\n        cv2.waitKey(1)\n\n    # Release the video capture and close the OpenCV window\n    video_capture.release()\n    cv2.destroyAllWindows()\n\n# Get the selected Read node\nselected_node = nuke.selectedNode()\n\n# Ensure the selected node is a Read node\nif selected_node.Class() == \"Read\":\n    track_face(selected_node, start_frame, end_frame)\nelse:\n    nuke.message(\"Please select a Read node.\")\n" +STARTLINE}
addUserKnob {26 "" +STARTLINE}
addUserKnob {7 scaleFactor R 0 2}
scaleFactor 2
addUserKnob {3 minNeighbors}
minNeighbors 5
addUserKnob {3 minSizeX}
minSizeX 30
addUserKnob {3 minSizeY}
minSizeY 30
}
